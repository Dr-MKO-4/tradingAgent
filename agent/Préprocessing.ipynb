{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cb573d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fda1e97",
   "metadata": {},
   "source": [
    "## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "657c21d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date    Adj Close        Close         High          Low  \\\n",
      "0  2020-01-03  7344.884277  7344.884277  7413.715332  6914.996094   \n",
      "1  2020-01-04  7410.656738  7410.656738  7427.385742   7309.51416   \n",
      "2  2020-01-05  7411.317383  7411.317383   7544.49707  7400.535645   \n",
      "3  2020-01-06  7769.219238  7769.219238  7781.867188  7409.292969   \n",
      "4  2020-01-07  8163.692383  8163.692383   8178.21582  7768.227539   \n",
      "\n",
      "          Open       Volume  \n",
      "0  6984.428711  28111481032  \n",
      "1  7345.375488  18444271275  \n",
      "2   7410.45166  19725074095  \n",
      "3  7410.452148  23276261598  \n",
      "4  7768.682129  28767291327  \n",
      "         Date   Adj Close       Close        High         Low        Open  \\\n",
      "0  2020-01-03  134.171707  134.171707  134.554016  126.490021  127.411263   \n",
      "1  2020-01-04  135.069366  135.069366  136.052719  133.040558  134.168518   \n",
      "2  2020-01-05  136.276779  136.276779  139.410202  135.045624  135.072098   \n",
      "3  2020-01-06  144.304153  144.304153  144.328186  136.079636  136.305542   \n",
      "4  2020-01-07  143.543991  143.543991   145.00177  140.488876  144.311996   \n",
      "\n",
      "        Volume  \n",
      "0  10476845358  \n",
      "1   7430904515  \n",
      "2   7526675353  \n",
      "3   9093747121  \n",
      "4   9257954672  \n",
      "         Date Adj Close     Close      High       Low      Open    Volume\n",
      "0  2020-04-12  0.882507  0.882507   0.95667  0.762426  0.785448  38736897\n",
      "1  2020-04-13  0.777832  0.777832  0.891603  0.773976   0.89076  18211285\n",
      "2  2020-04-14  0.661925  0.661925  0.796472  0.628169  0.777832  16747614\n",
      "3  2020-04-15  0.646651  0.646651  0.704964  0.621531  0.669289  13075275\n",
      "4  2020-04-16  0.690816  0.690816  0.774192  0.625107  0.630879  21346031\n",
      "         Date  Adj Close      Close       High        Low       Open  \\\n",
      "0  2020-01-03  13.660452  13.660452  13.763709  13.012638  13.035329   \n",
      "1  2020-01-04  13.891512  13.891512  13.921914  13.560008  13.667442   \n",
      "2  2020-01-05  14.111019  14.111019  14.410801  13.886547   13.88834   \n",
      "3  2020-01-06  14.957808  14.957808  15.003565   14.11124   14.11124   \n",
      "4  2020-01-07   15.00925   15.00925  15.135275  14.568403  14.966209   \n",
      "\n",
      "      Volume  \n",
      "0  173683857  \n",
      "1  182230374  \n",
      "2  202552703  \n",
      "3  224800409  \n",
      "4  191948560  \n",
      "         Date Adj Close     Close      High       Low      Open    Volume\n",
      "0  2020-01-03   0.03418   0.03418  0.034427  0.032491  0.032748  30162644\n",
      "1  2020-01-04  0.034595  0.034595  0.034685  0.033872  0.034191  29535781\n",
      "2  2020-01-05  0.034721  0.034721  0.035356  0.034545  0.034574  21479178\n",
      "3  2020-01-06  0.037272  0.037272  0.037299  0.034674  0.034751  37988444\n",
      "4  2020-01-07  0.037047  0.037047  0.037807  0.036653  0.037291  51562680\n",
      "         Date Adj Close     Close      High       Low      Open      Volume\n",
      "0  2020-01-03  0.193521  0.193521   0.19407  0.185846  0.187948  1270017043\n",
      "1  2020-01-04  0.194355  0.194355  0.194653  0.191835  0.193521   999331594\n",
      "2  2020-01-05  0.195537  0.195537  0.199223  0.193884  0.194367  1168067557\n",
      "3  2020-01-06   0.22151   0.22151  0.223832  0.195068  0.195536  2301679290\n",
      "4  2020-01-07  0.213917  0.213917  0.223386  0.209047  0.221576  2237698314\n",
      "         Date Adj Close     Close      High       Low      Open    Volume\n",
      "0  2020-01-03  0.002145  0.002145  0.002177  0.001991  0.002008  62619988\n",
      "1  2020-01-04  0.002241  0.002241   0.00249   0.00205  0.002144  94227582\n",
      "2  2020-01-05  0.002419  0.002419  0.002491  0.002117   0.00224  52631740\n",
      "3  2020-01-06  0.002463  0.002463  0.002564  0.002379  0.002418  54562409\n",
      "4  2020-01-07  0.002433  0.002433  0.002497  0.002354  0.002485  52767343\n",
      "         Date Adj Close     Close       High       Low      Open     Volume\n",
      "0  2020-09-22  5.234632  5.234632  11.463443   4.12538  4.986754  288098840\n",
      "1  2020-09-23  4.118469  4.118469    5.32931  3.982604  5.321654  173091214\n",
      "2  2020-09-24  4.566561  4.566561   4.751878  3.539887  3.817925   96110964\n",
      "3  2020-09-25  4.712279  4.712279   4.958673  4.240798  4.614028   55854397\n",
      "4  2020-09-26  4.539249  4.539249   4.817752  4.376774  4.713736   27304546\n",
      "         Date Adj Close     Close      High       Low      Open    Volume\n",
      "0  2020-01-03  0.015194  0.015194  0.015427  0.014297  0.014694  23635829\n",
      "1  2020-01-04  0.014961  0.014961  0.015523  0.014865   0.01517  16448623\n",
      "2  2020-01-05  0.014914  0.014914  0.015278  0.014837  0.014954  13314381\n",
      "3  2020-01-06  0.015587  0.015587  0.015924  0.014878  0.014908  24130445\n",
      "4  2020-01-07    0.0151    0.0151  0.015721  0.014838  0.015587  25141593\n",
      "         Date  Adj Close      Close       High        Low       Open  \\\n",
      "0  2020-01-03  42.415573  42.415573  42.447174  39.450844  39.863129   \n",
      "1  2020-01-04  43.326607  43.326607  43.342705  41.933075  42.383526   \n",
      "2  2020-01-05  43.553207  43.553207  44.733616  42.998535  43.291382   \n",
      "3  2020-01-06  45.816353  45.816353  45.957878  43.494373  43.603893   \n",
      "4  2020-01-07  46.424583  46.424583  46.858387  44.723019   45.83868   \n",
      "\n",
      "       Volume  \n",
      "0  3260961326  \n",
      "1  2843192897  \n",
      "2  3017148033  \n",
      "3  3349237768  \n",
      "4  3611521907  \n"
     ]
    }
   ],
   "source": [
    "names=['BTC-USD', 'ETH-USD', 'SOL-USD', 'BNB-USD', 'ADA-USD',\n",
    "    'XRP-USD', 'DOGE-USD', 'AVAX-USD', 'MATIC-USD', 'LTC-USD']\n",
    "for name in names:\n",
    "    # Read the dataset\n",
    "    dataset = pd.read_csv(fr'M:\\Ecole\\tradingAgent\\data\\exports\\{name}.csv')\n",
    "    data=dataset.iloc[2:,:].values\n",
    "    data=pd.DataFrame(data=data, columns=['Date']+dataset.columns[1:].tolist())\n",
    "    print(data.head(5))\n",
    "    data.to_csv(fr'M:\\Ecole\\tradingAgent\\data\\exports\\{name}.csv', index=False)\n",
    "    # Convert the 'Date' column to datetime format\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y-%m-%d')\n",
    "    # Set the 'Date' column as the index\n",
    "    data.set_index('Date', inplace=True)\n",
    "    # Convert the data to numeric values\n",
    "    data = data.apply(pd.to_numeric, errors='coerce')\n",
    "    # Drop rows with NaN values\n",
    "    data.dropna(inplace=True)\n",
    "    data.to_csv(fr'M:\\Ecole\\tradingAgent\\data\\exports\\{name}.csv', index=False)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2026285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b5ec6b",
   "metadata": {},
   "source": [
    "# ─── 1) DQNAgent  ────────────────\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0a0e677",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DQNAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_size,\n",
    "        action_size,\n",
    "        gamma=0.95,\n",
    "        epsilon=1.0,\n",
    "        epsilon_min=0.01,\n",
    "        epsilon_decay=0.995,\n",
    "        learning_rate=0.001,\n",
    "        activation='relu',\n",
    "        loss='mse',\n",
    "        optimizer=Adam,\n",
    "        epochs=1,\n",
    "        memory_size=2000\n",
    "    ):\n",
    "        self.state_size    = state_size\n",
    "        self.action_size   = action_size\n",
    "        self.memory        = deque(maxlen=memory_size)\n",
    "        self.gamma         = gamma\n",
    "        self.epsilon       = epsilon\n",
    "        self.epsilon_min   = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.learning_rate= learning_rate\n",
    "        self.activation   = activation\n",
    "        self.loss         = loss\n",
    "        self.optimizer    = optimizer\n",
    "        self.epochs       = epochs\n",
    "\n",
    "        # réseau principal et réseau cible\n",
    "        self.model        = self._build_model()\n",
    "        self.target_model = self._build_model()\n",
    "        self.update_target_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        m = Sequential()\n",
    "        m.add(Dense(64, input_dim=self.state_size, activation=self.activation))\n",
    "        m.add(Dense(64, activation=self.activation))\n",
    "        m.add(Dense(self.action_size, activation='linear'))\n",
    "        m.compile(loss=self.loss, optimizer=self.optimizer(learning_rate=self.learning_rate))\n",
    "        return m\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        q = self.model.predict(state[np.newaxis,:], verbose=0)[0]\n",
    "        return np.argmax(q)\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        batch = random.sample(self.memory, min(len(self.memory), batch_size))\n",
    "        for state, action, reward, next_state, done in batch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                future = np.max(self.target_model.predict(next_state[np.newaxis,:], verbose=0)[0])\n",
    "                target = reward + self.gamma * future\n",
    "            q_vals = self.model.predict(state[np.newaxis,:], verbose=0)\n",
    "            q_vals[0][action] = target\n",
    "            self.model.fit(state[np.newaxis,:], q_vals, epochs=self.epochs, verbose=0)\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "\n",
    "    def save(self, path):\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        self.model.save(path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.model = load_model(path)\n",
    "        self.update_target_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3885e722",
   "metadata": {},
   "source": [
    "# ─── 2) CryptoEnv pour lecture CSV nettoyés ────────────────────────────────────\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ea91bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CryptoEnv:\n",
    "    def __init__(self, csv_path, window_size=10, initial_balance=1.0):\n",
    "        df = pd.read_csv(csv_path, parse_dates=['Date'], index_col='Date')\n",
    "        self.prices = df['Close'].values\n",
    "        self.window_size = window_size\n",
    "        self.initial_balance = initial_balance\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.t = self.window_size\n",
    "        self.balance = self.initial_balance\n",
    "        self.position = 0    # 0 = flat, 1 = long, -1 = short\n",
    "        self.entry_price = 0\n",
    "        return self._get_state()\n",
    "\n",
    "    def _get_state(self):\n",
    "        # vecteur des rendements sur la fenêtre\n",
    "        window = self.prices[self.t-self.window_size:self.t]\n",
    "        returns = np.diff(window) / window[:-1]\n",
    "        # si besoin, on peut concatener position, balance, etc.\n",
    "        return returns\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        action: 0=hold, 1=buy(long), 2=sell(short)\n",
    "        \"\"\"\n",
    "        price_today = self.prices[self.t]\n",
    "        price_next  = self.prices[self.t+1]\n",
    "        reward = 0.0\n",
    "\n",
    "        # exécution de l’ordre\n",
    "        if action == 1 and self.position == 0:  # ouverture long\n",
    "            self.position = 1\n",
    "            self.entry_price = price_today\n",
    "        elif action == 2 and self.position == 0:  # ouverture short\n",
    "            self.position = -1\n",
    "            self.entry_price = price_today\n",
    "        # on ne gère pas de fermeture explicite, on calcule P&L à la fin de la journée suivante\n",
    "        # calcul du reward immédiat\n",
    "        if self.position != 0:\n",
    "            pnl = (price_next - self.entry_price) * self.position\n",
    "            reward = pnl\n",
    "            # on clôture chaque jour pour simplifier\n",
    "            self.balance += pnl\n",
    "            self.position = 0\n",
    "\n",
    "        self.t += 1\n",
    "        done = (self.t >= len(self.prices)-1)\n",
    "        next_state = self._get_state()\n",
    "        return next_state, reward, done\n",
    "\n",
    "    def portfolio_value(self):\n",
    "        return self.balance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b499857",
   "metadata": {},
   "source": [
    "# ─── 3) Boucle d’entraînement sur tous les symbols ───────────────────────────────\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fdd1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    symbols = ['BTC-USD','ETH-USD','SOL-USD','BNB-USD','ADA-USD',\n",
    "               'XRP-USD','DOGE-USD','AVAX-USD','MATIC-USD','LTC-USD']\n",
    "\n",
    "    window_size = 10\n",
    "    episodes = 50\n",
    "    batch_size = 32\n",
    "\n",
    "    for symbol in symbols:\n",
    "        print(f\"\\n=== Training on {symbol} ===\")\n",
    "        env   = CryptoEnv(f\"data/exports/{symbol}.csv\", window_size=window_size)\n",
    "        agent = DQNAgent(state_size=window_size-1, action_size=3)\n",
    "\n",
    "        for e in range(episodes):\n",
    "            state = env.reset()\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "            while not done:\n",
    "                action = agent.act(state)\n",
    "                next_state, reward, done = env.step(action)\n",
    "                agent.remember(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "\n",
    "            agent.replay(batch_size)\n",
    "            agent.update_target_model()\n",
    "            print(f\"Episode {e+1}/{episodes} — total_reward={total_reward:.4f} — ε={agent.epsilon:.3f}\")\n",
    "\n",
    "        # sauvegarde modèle par symbole\n",
    "        agent.save(f\"models/dqn_{symbol.replace('/','_')}.h5\")\n",
    "        print(f\"Model saved for {symbol}\")\n",
    "\n",
    "    print(\"=== All trainings done ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
